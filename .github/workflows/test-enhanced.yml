name: Enhanced Testing Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run nightly tests at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      rust_version:
        description: 'Rust version to test'
        required: false
        default: 'stable'

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  RUSTFLAGS: "-C instrument-coverage"
  LLVM_PROFILE_FILE: "balatro-%p-%m.profraw"

jobs:
  test-matrix:
    name: Test - ${{ matrix.rust }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}

    strategy:
      fail-fast: false
      matrix:
        rust: [stable, beta, nightly, 1.70.0]  # MSRV
        os: [ubuntu-latest, windows-latest, macos-latest]
        exclude:
          # Exclude some combinations to save CI time
          - rust: beta
            os: windows-latest
          - rust: nightly
            os: windows-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for coverage

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ matrix.rust }}
          components: rustfmt, clippy, llvm-tools-preview

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: ~/.cargo/registry
          key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}

      - name: Cache cargo index
        uses: actions/cache@v4
        with:
          path: ~/.cargo/git
          key: ${{ runner.os }}-cargo-index-${{ hashFiles('**/Cargo.lock') }}

      - name: Cache cargo build
        uses: actions/cache@v4
        with:
          path: target
          key: ${{ runner.os }}-cargo-build-${{ matrix.rust }}-${{ hashFiles('**/Cargo.lock') }}

      - name: Run tests
        run: |
          cargo test --all-features --workspace -- --nocapture
          cargo test --doc

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.os }}-${{ matrix.rust }}
          path: |
            target/test-results/
            **/*.profraw

  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    needs: test-matrix

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust stable
        uses: dtolnay/rust-toolchain@stable
        with:
          components: llvm-tools-preview

      - name: Install cargo-llvm-cov
        run: cargo install cargo-llvm-cov

      - name: Generate coverage report
        run: |
          cargo llvm-cov --workspace --all-features --lcov --output-path lcov.info
          cargo llvm-cov report --html --output-dir coverage-report

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./lcov.info
          fail_ci_if_error: true
          verbose: true

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage-report/

      - name: Check coverage threshold
        run: |
          COVERAGE=$(cargo llvm-cov report --json | jq '.totals.lines.percent')
          echo "Coverage: $COVERAGE%"
          if (( $(echo "$COVERAGE < 70" | bc -l) )); then
            echo "Coverage below 70% threshold!"
            exit 1
          fi

  performance-regression:
    name: Performance Regression Check
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Need previous commit

      - name: Install Rust stable
        uses: dtolnay/rust-toolchain@stable

      - name: Install cargo-criterion
        run: cargo install cargo-criterion

      - name: Cache benchmark data
        uses: actions/cache@v4
        with:
          path: target/criterion
          key: ${{ runner.os }}-benchmark-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-benchmark-

      - name: Run benchmarks
        run: |
          cargo criterion --workspace --message-format json > criterion-results.json

      - name: Compare with baseline
        if: github.event_name == 'pull_request'
        run: |
          git checkout HEAD^
          cargo criterion --workspace --message-format json > criterion-baseline.json

          # Simple comparison script
          python3 -c "
          import json
          import sys

          with open('criterion-baseline.json') as f:
              baseline = json.load(f)
          with open('criterion-results.json') as f:
              current = json.load(f)

          regressions = []
          for test in current.get('tests', []):
              name = test['name']
              current_time = test.get('mean', 0)
              baseline_test = next((t for t in baseline.get('tests', []) if t['name'] == name), None)
              if baseline_test:
                  baseline_time = baseline_test.get('mean', 0)
                  if baseline_time > 0:
                      change = ((current_time - baseline_time) / baseline_time) * 100
                      if change > 10:  # 10% regression threshold
                          regressions.append(f'{name}: {change:.1f}% slower')

          if regressions:
              print('Performance regressions detected:')
              for r in regressions:
                  print(f'  - {r}')
              sys.exit(1)
          else:
              print('No performance regressions detected')
          "

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            criterion-results.json
            target/criterion/

  parallel-tests:
    name: Parallel Test Execution
    runs-on: ubuntu-latest

    strategy:
      matrix:
        partition: [1, 2, 3, 4]

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust stable
        uses: dtolnay/rust-toolchain@stable

      - name: Install cargo-nextest
        run: cargo install cargo-nextest

      - name: Run tests (partition ${{ matrix.partition }}/4)
        run: |
          cargo nextest run \
            --workspace \
            --partition count:${{ matrix.partition }}/4 \
            --profile ci \
            --test-threads 4

      - name: Upload test report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nextest-report-partition-${{ matrix.partition }}
          path: target/nextest/ci/junit.xml

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, coverage, performance-regression, parallel-tests]
    if: always()

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4

      - name: Generate summary report
        run: |
          echo "# Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Test Matrix Status" >> $GITHUB_STEP_SUMMARY
          echo "| OS | Rust Version | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|---|---|---|" >> $GITHUB_STEP_SUMMARY

          # Process test results
          for result in test-results-*; do
            if [ -d "$result" ]; then
              os=$(echo $result | cut -d'-' -f3)
              rust=$(echo $result | cut -d'-' -f4)
              echo "| $os | $rust | âœ… |" >> $GITHUB_STEP_SUMMARY
            fi
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Coverage Report" >> $GITHUB_STEP_SUMMARY
          if [ -f "coverage-report/index.html" ]; then
            echo "Coverage report available in artifacts" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Performance" >> $GITHUB_STEP_SUMMARY
          if [ -f "criterion-results.json" ]; then
            echo "Benchmark results available in artifacts" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync(process.env.GITHUB_STEP_SUMMARY, 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
